#!/usr/bin/env python3
"""
åƒè€ƒåœ–ç‰‡æŒ‡å°ç”Ÿæˆå™¨
ä½¿ç”¨img2imgå’ŒReference ControlNetç¢ºä¿ç”Ÿæˆçš„è§’è‰²èˆ‡åƒè€ƒåœ–ç‰‡ä¸€è‡´
"""

import os
import yaml
import torch
from pathlib import Path
from PIL import Image, ImageEnhance, ImageFilter
import numpy as np
from rich.console import Console
from rich.progress import Progress, BarColumn, TextColumn
from typing import List, Optional

# Diffusers ç›¸é—œå°å…¥
from diffusers import (
    StableDiffusionImg2ImgPipeline,
    StableDiffusionControlNetPipeline,
    ControlNetModel,
    DPMSolverMultistepScheduler
)
from controlnet_aux import OpenposeDetector
import cv2

console = Console()

class ReferenceGuidedGenerator:
    def __init__(self, config_path: str = "configs/generation_config.yaml"):
        """åˆå§‹åŒ–åƒè€ƒåœ–ç‰‡æŒ‡å°ç”Ÿæˆå™¨"""
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        if torch.backends.mps.is_available():
            self.device = "mps"
        
        self.output_dir = Path("output/reference_guided")
        self.output_dir.mkdir(exist_ok=True, parents=True)
        
        console.print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {self.device}", style="blue")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.img2img_pipe = None
        self.reference_path = None
        self._load_models()
    
    def _load_models(self):
        """è¼‰å…¥img2imgæ¨¡å‹"""
        console.print("ğŸ“¦ è¼‰å…¥img2imgæ¨¡å‹ä¸­...", style="bold yellow")
        
        try:
            # è¼‰å…¥img2imgç®¡ç·š
            self.img2img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
                self.config['model_settings']['base_model'],
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                safety_checker=None,
            )
            
            # è¨­å®šèª¿åº¦å™¨
            self.img2img_pipe.scheduler = DPMSolverMultistepScheduler.from_config(
                self.img2img_pipe.scheduler.config
            )
            
            # å•Ÿç”¨è¨˜æ†¶é«”å„ªåŒ–
            if self.device == "cuda":
                self.img2img_pipe.enable_model_cpu_offload()
                self.img2img_pipe.enable_xformers_memory_efficient_attention()
            
            self.img2img_pipe = self.img2img_pipe.to(self.device)
            
            console.print("âœ… img2imgæ¨¡å‹è¼‰å…¥å®Œæˆ", style="green")
            
        except Exception as e:
            console.print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}", style="red")
    
    def load_reference_image(self, reference_path: str) -> Image.Image:
        """è¼‰å…¥ä¸¦é è™•ç†åƒè€ƒåœ–ç‰‡"""
        self.reference_path = reference_path
        
        if not Path(reference_path).exists():
            raise FileNotFoundError(f"åƒè€ƒåœ–ç‰‡ä¸å­˜åœ¨: {reference_path}")
        
        # è¼‰å…¥åƒè€ƒåœ–ç‰‡
        ref_image = Image.open(reference_path)
        
        # ç¢ºä¿æ˜¯RGBAæ ¼å¼
        if ref_image.mode != 'RGBA':
            ref_image = ref_image.convert('RGBA')
        
        console.print(f"âœ… è¼‰å…¥åƒè€ƒåœ–ç‰‡: {reference_path}", style="green")
        console.print(f"ğŸ“ åŸå§‹å°ºå¯¸: {ref_image.size}", style="cyan")
        
        return ref_image
    
    def prepare_reference_for_generation(self, ref_image: Image.Image, 
                                       target_size: tuple = (256, 384)) -> Image.Image:
        """æº–å‚™åƒè€ƒåœ–ç‰‡ç”¨æ–¼ç”Ÿæˆ"""
        
        # æ”¾å¤§åˆ°ç›®æ¨™å°ºå¯¸ï¼ˆä½¿ç”¨æœ€è¿‘é„°æ’å€¼ä¿æŒåƒç´ é¢¨æ ¼ï¼‰
        upscaled = ref_image.resize(target_size, Image.NEAREST)
        
        # è¼•å¾®æ¨¡ç³Šä»¥é¿å…éåº¦æ“¬åˆ
        blurred = upscaled.filter(ImageFilter.GaussianBlur(radius=0.5))
        
        # é™ä½é€æ˜åº¦ä»¥æ¸›å°‘ç›´æ¥è¤‡è£½
        if blurred.mode == 'RGBA':
            # å°‡alphaé€šé“ç¨å¾®é™ä½
            alpha = np.array(blurred)[:, :, 3]
            alpha = (alpha * 0.8).astype(np.uint8)
            blurred_array = np.array(blurred)
            blurred_array[:, :, 3] = alpha
            blurred = Image.fromarray(blurred_array, 'RGBA')
        
        return blurred
    
    def create_walking_variations(self, base_ref: Image.Image, frame_count: int = 8) -> List[Image.Image]:
        """åŸºæ–¼åƒè€ƒåœ–ç‰‡å‰µå»ºè¡Œèµ°å‹•ç•«è®ŠåŒ–"""
        variations = []
        
        for i in range(frame_count):
            # è¨ˆç®—è¡Œèµ°é€±æœŸé€²åº¦
            cycle_progress = i / frame_count
            
            # å‰µå»ºè¼•å¾®çš„å§¿å‹¢è®ŠåŒ–
            modified_ref = self.apply_walking_transform(base_ref, cycle_progress)
            variations.append(modified_ref)
        
        return variations
    
    def apply_walking_transform(self, image: Image.Image, progress: float) -> Image.Image:
        """æ‡‰ç”¨è¡Œèµ°å‹•ç•«è®Šæ›"""
        # è½‰æ›ç‚ºnumpyé™£åˆ—
        img_array = np.array(image)
        h, w = img_array.shape[:2]
        
        # è¨ˆç®—è¼•å¾®çš„å·¦å³æ–æ“º
        sway = int(2 * np.sin(2 * np.pi * progress))
        
        # å‰µå»ºè®Šæ›çŸ©é™£ï¼ˆè¼•å¾®æ–æ“ºï¼‰
        if sway != 0:
            # è¼•å¾®æ°´å¹³ç§»å‹•
            shifted = np.roll(img_array, sway, axis=1)
            return Image.fromarray(shifted, image.mode)
        
        return image
    
    def generate_frame_from_reference(self, 
                                    reference_img: Image.Image,
                                    frame_idx: int,
                                    character_name: str) -> Image.Image:
        """åŸºæ–¼åƒè€ƒåœ–ç‰‡ç”Ÿæˆå–®å¹€"""
        
        # æ§‹å»ºæç¤ºè©
        char_config = self.config['prompts']['character_templates'].get(character_name, {})
        base_prompt = self.config['prompts']['base_positive']
        char_prompt = char_config.get('positive', '')
        
        # å‰µå»ºæ›´å¼·èª¿ä¸€è‡´æ€§çš„æç¤ºè©
        full_prompt = f"{base_prompt}, {char_prompt}, walking animation frame {frame_idx}, consistent character design, same outfit, same hairstyle"
        negative_prompt = f"{self.config['prompts']['base_negative']}, different character, changed outfit, different hairstyle"
        
        # img2imgç”Ÿæˆåƒæ•¸
        gen_params = {
            "prompt": full_prompt,
            "negative_prompt": negative_prompt,
            "image": reference_img,
            "strength": 0.3,  # è¼ƒä½çš„strengthä¿æŒåƒè€ƒåœ–ç‰‡ç‰¹å¾µ
            "num_inference_steps": self.config['generation_params']['num_inference_steps'],
            "guidance_scale": self.config['generation_params']['guidance_scale'],
            "generator": torch.Generator(device=self.device).manual_seed(42 + frame_idx),
        }
        
        try:
            # ç”Ÿæˆåœ–åƒ
            with torch.no_grad():
                result = self.img2img_pipe(**gen_params)
                generated_image = result.images[0]
            
            return generated_image
            
        except Exception as e:
            console.print(f"âŒ ç”Ÿæˆå¹€ {frame_idx} å¤±æ•—: {e}", style="red")
            # è¿”å›åƒè€ƒåœ–ç‰‡ä½œç‚ºå¾Œå‚™
            return reference_img
    
    def generate_kelly_walking_cycle(self, reference_path: str) -> List[Image.Image]:
        """å°ˆé–€ç‚ºKellyç”Ÿæˆè¡Œèµ°é€±æœŸ"""
        console.print("ğŸ¯ é–‹å§‹åŸºæ–¼åƒè€ƒåœ–ç‰‡ç”ŸæˆKellyè¡Œèµ°é€±æœŸ", style="bold magenta")
        
        # è¼‰å…¥åƒè€ƒåœ–ç‰‡
        ref_image = self.load_reference_image(reference_path)
        
        # æº–å‚™ç”Ÿæˆç”¨çš„åƒè€ƒåœ–ç‰‡
        target_size = (self.config['image_settings']['width'], 
                      self.config['image_settings']['height'])
        prepared_ref = self.prepare_reference_for_generation(ref_image, target_size)
        
        # å‰µå»ºè¡Œèµ°è®ŠåŒ–
        walking_refs = self.create_walking_variations(prepared_ref, 8)
        
        frames = []
        
        with Progress(
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            console=console
        ) as progress:
            task = progress.add_task("ç”ŸæˆKellyè¡Œèµ°å¹€", total=len(walking_refs))
            
            for i, ref_variant in enumerate(walking_refs):
                # ç”ŸæˆåŸºæ–¼åƒè€ƒçš„å¹€
                frame = self.generate_frame_from_reference(ref_variant, i, "kelly")
                frames.append(frame)
                
                # ä¿å­˜å¹€
                frame_path = self.output_dir / f"kelly_ref_frame_{i:02d}.png"
                frame.save(frame_path, "PNG")
                
                progress.update(task, advance=1,
                              description=f"Kellyåƒè€ƒç”Ÿæˆ ç¬¬ {i+1}/{len(walking_refs)} å¹€")
        
        console.print("âœ… Kellyåƒè€ƒæŒ‡å°ç”Ÿæˆå®Œæˆ", style="green")
        return frames
    
    def create_simple_reference_copy(self, reference_path: str, output_count: int = 8):
        """å‰µå»ºç°¡å–®çš„åƒè€ƒåœ–ç‰‡è¤‡è£½ç‰ˆæœ¬ï¼ˆä½œç‚ºå°æ¯”ï¼‰"""
        console.print("ğŸ“‹ å‰µå»ºåƒè€ƒåœ–ç‰‡è®ŠåŒ–ç‰ˆæœ¬", style="blue")
        
        ref_image = self.load_reference_image(reference_path)
        
        for i in range(output_count):
            # å‰µå»ºè¼•å¾®è®ŠåŒ–
            if i == 0:
                # åŸå§‹ç‰ˆæœ¬
                output_img = ref_image
            elif i < 4:
                # è¼•å¾®å¢å¼·ç‰ˆæœ¬
                enhancer = ImageEnhance.Contrast(ref_image)
                output_img = enhancer.enhance(1.1 + i * 0.05)
            else:
                # è¼•å¾®è‰²èª¿è®ŠåŒ–
                enhancer = ImageEnhance.Color(ref_image)
                output_img = enhancer.enhance(1.1 + (i-4) * 0.03)
            
            # æ”¾å¤§åˆ°æ¨™æº–å°ºå¯¸
            target_size = (self.config['image_settings']['width'], 
                          self.config['image_settings']['height'])
            upscaled = output_img.resize(target_size, Image.NEAREST)
            
            # ä¿å­˜
            output_path = self.output_dir / f"kelly_simple_copy_{i:02d}.png"
            upscaled.save(output_path, "PNG")
            
            console.print(f"âœ… ä¿å­˜è®ŠåŒ–ç‰ˆæœ¬: {output_path.name}", style="green")
    
    def cleanup(self):
        """æ¸…ç†è¨˜æ†¶é«”"""
        if self.img2img_pipe is not None:
            del self.img2img_pipe
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        console.print("ğŸ§¹ è¨˜æ†¶é«”æ¸…ç†å®Œæˆ", style="blue")

def main():
    """ä¸»å‡½æ•¸"""
    generator = ReferenceGuidedGenerator()
    
    try:
        # Kellyåƒè€ƒåœ–ç‰‡è·¯å¾‘
        kelly_ref_path = "data/raw_sprites/Kelly.png"
        
        if Path(kelly_ref_path).exists():
            # æ–¹æ³•1: å‰µå»ºç°¡å–®è¤‡è£½ç‰ˆæœ¬
            generator.create_simple_reference_copy(kelly_ref_path)
            
            # æ–¹æ³•2: AIæŒ‡å°ç”Ÿæˆ
            generator.generate_kelly_walking_cycle(kelly_ref_path)
            
            console.print("\nğŸ‰ Kellyåƒè€ƒæŒ‡å°ç”Ÿæˆå®Œæˆï¼", style="bold green")
            console.print("ğŸ“ è«‹æŸ¥çœ‹ output/reference_guided/ ç›®éŒ„", style="cyan")
        else:
            console.print(f"âŒ æ‰¾ä¸åˆ°Kellyåƒè€ƒåœ–ç‰‡: {kelly_ref_path}", style="red")
    
    finally:
        generator.cleanup()

if __name__ == "__main__":
    main() 