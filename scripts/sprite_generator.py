#!/usr/bin/env python3
"""
æ¥“ä¹‹è°·é¢¨æ ¼è§’è‰²è¡Œèµ°åœ–ç”Ÿæˆå™¨
ä½¿ç”¨Stable Diffusion + ControlNetç”Ÿæˆä¸€è‡´æ€§çš„è§’è‰²è¡Œèµ°å‹•ç•«
"""

import os
import yaml
import torch
from pathlib import Path
from PIL import Image
import numpy as np
from rich.console import Console
from rich.progress import Progress, BarColumn, TextColumn
from typing import List, Optional, Dict, Any

# Diffusers ç›¸é—œå°å…¥
from diffusers import (
    StableDiffusionControlNetPipeline,
    ControlNetModel,
    DPMSolverMultistepScheduler,
    StableDiffusionPipeline
)
from diffusers.utils import load_image
from transformers import pipeline
import cv2

console = Console()

class SpriteGenerator:
    def __init__(self, config_path: str = "configs/generation_config.yaml"):
        """åˆå§‹åŒ–ç²¾éˆç”Ÿæˆå™¨"""
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.output_dir = Path("output/frames")
        self.output_dir.mkdir(exist_ok=True, parents=True)
        
        console.print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {self.device}", style="blue")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.pipe = None
        self.controlnet = None
        self._load_models()
    
    def _load_models(self):
        """è¼‰å…¥Stable Diffusionå’ŒControlNetæ¨¡å‹"""
        console.print("ğŸ“¦ è¼‰å…¥AIæ¨¡å‹ä¸­...", style="bold yellow")
        
        try:
            # è¼‰å…¥ControlNet
            self.controlnet = ControlNetModel.from_pretrained(
                self.config['controlnet']['model'],
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
            )
            
            # è¼‰å…¥ä¸»è¦SDç®¡ç·š
            self.pipe = StableDiffusionControlNetPipeline.from_pretrained(
                self.config['model_settings']['base_model'],
                controlnet=self.controlnet,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                safety_checker=None,  # é—œé–‰å®‰å…¨æª¢æŸ¥å™¨ä»¥ç¯€çœè¨˜æ†¶é«”
            )
            
            # è¨­å®šèª¿åº¦å™¨
            self.pipe.scheduler = DPMSolverMultistepScheduler.from_config(
                self.pipe.scheduler.config
            )
            
            # å•Ÿç”¨è¨˜æ†¶é«”å„ªåŒ–
            if self.device == "cuda":
                self.pipe.enable_model_cpu_offload()
                self.pipe.enable_xformers_memory_efficient_attention()
            
            self.pipe = self.pipe.to(self.device)
            
            console.print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ", style="green")
            
        except Exception as e:
            console.print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}", style="red")
            # ä½¿ç”¨åŸºç¤æ¨¡å‹ä½œç‚ºå¾Œå‚™
            self._load_fallback_model()
    
    def _load_fallback_model(self):
        """è¼‰å…¥å¾Œå‚™åŸºç¤æ¨¡å‹"""
        console.print("ğŸ”„ è¼‰å…¥åŸºç¤æ¨¡å‹...", style="yellow")
        
        self.pipe = StableDiffusionPipeline.from_pretrained(
            self.config['model_settings']['base_model'],
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
        )
        self.pipe = self.pipe.to(self.device)
    
    def create_pose_conditioning(self, frame_idx: int) -> np.ndarray:
        """å‰µå»ºå§¿å‹¢æ§åˆ¶åœ–åƒ"""
        # å‰µå»ºåŸºæœ¬çš„è¡Œèµ°å§¿å‹¢éª¨æ¶
        img_size = (self.config['image_settings']['width'], 
                   self.config['image_settings']['height'])
        
        # å‰µå»ºç©ºç™½åœ–åƒ
        pose_img = np.zeros((*img_size[::-1], 3), dtype=np.uint8)
        
        # è¨ˆç®—è¡Œèµ°é€±æœŸä¸­çš„ä½ç½®
        cycle_progress = frame_idx / self.config['animation']['walk_cycle_frames']
        
        # åŸºæœ¬äººé«”æ¯”ä¾‹ï¼ˆç›¸å°æ–¼åœ–åƒå¤§å°ï¼‰
        center_x = img_size[0] // 2
        head_y = int(img_size[1] * 0.15)
        torso_y = int(img_size[1] * 0.5)
        hip_y = int(img_size[1] * 0.65)
        foot_y = int(img_size[1] * 0.9)
        
        # è¡Œèµ°å‹•ä½œçš„è…¿éƒ¨åç§»
        leg_offset = int(30 * np.sin(2 * np.pi * cycle_progress))
        
        # ç¹ªè£½ç°¡å–®çš„éª¨æ¶
        # é ­éƒ¨
        cv2.circle(pose_img, (center_x, head_y), 15, (255, 255, 255), 2)
        
        # è»€å¹¹
        cv2.line(pose_img, (center_x, head_y + 15), (center_x, hip_y), (255, 255, 255), 3)
        
        # æ‰‹è‡‚
        arm_offset = int(20 * np.cos(2 * np.pi * cycle_progress))
        cv2.line(pose_img, (center_x, torso_y), (center_x - 40 + arm_offset, torso_y + 30), (255, 255, 255), 3)
        cv2.line(pose_img, (center_x, torso_y), (center_x + 40 - arm_offset, torso_y + 30), (255, 255, 255), 3)
        
        # è…¿éƒ¨
        cv2.line(pose_img, (center_x, hip_y), (center_x - 15 + leg_offset, foot_y), (255, 255, 255), 3)
        cv2.line(pose_img, (center_x, hip_y), (center_x + 15 - leg_offset, foot_y), (255, 255, 255), 3)
        
        return pose_img
    
    def generate_character_frame(self, 
                               character_type: str, 
                               frame_idx: int, 
                               pose_image: Optional[np.ndarray] = None) -> Image.Image:
        """ç”Ÿæˆå–®å¹€è§’è‰²åœ–åƒ"""
        
        # æ§‹å»ºæç¤ºè©
        base_prompt = self.config['prompts']['base_positive']
        char_prompt = self.config['prompts']['character_templates'][character_type]['positive']
        full_prompt = f"{base_prompt}, {char_prompt}, frame {frame_idx}"
        
        negative_prompt = self.config['prompts']['base_negative']
        
        # ç”Ÿæˆåƒæ•¸
        gen_params = {
            "prompt": full_prompt,
            "negative_prompt": negative_prompt,
            "width": self.config['image_settings']['width'],
            "height": self.config['image_settings']['height'],
            "num_inference_steps": self.config['generation_params']['num_inference_steps'],
            "guidance_scale": self.config['generation_params']['guidance_scale'],
            "generator": torch.Generator(device=self.device).manual_seed(42 + frame_idx),
        }
        
        # å¦‚æœæœ‰ControlNetå’Œå§¿å‹¢åœ–åƒ
        if self.controlnet is not None and pose_image is not None:
            pose_pil = Image.fromarray(pose_image)
            gen_params["image"] = pose_pil
            gen_params["controlnet_conditioning_scale"] = self.config['controlnet']['conditioning_scale']
        
        try:
            # ç”Ÿæˆåœ–åƒ
            with torch.no_grad():
                result = self.pipe(**gen_params)
                image = result.images[0]
            
            return image
            
        except Exception as e:
            console.print(f"âŒ ç”Ÿæˆå¹€ {frame_idx} å¤±æ•—: {e}", style="red")
            # è¿”å›ç©ºç™½åœ–åƒä½œç‚ºå¾Œå‚™
            return Image.new('RGBA', 
                           (self.config['image_settings']['width'], 
                            self.config['image_settings']['height']), 
                           (255, 255, 255, 0))
    
    def generate_walk_cycle(self, character_type: str) -> List[Image.Image]:
        """ç”Ÿæˆå®Œæ•´çš„è¡Œèµ°é€±æœŸ"""
        console.print(f"ğŸ¨ ç”Ÿæˆ {character_type} è§’è‰²è¡Œèµ°é€±æœŸ...", style="bold blue")
        
        frames = []
        num_frames = self.config['animation']['walk_cycle_frames']
        
        with Progress(
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            console=console
        ) as progress:
            task = progress.add_task(f"ç”Ÿæˆ {character_type} å¹€æ•¸", total=num_frames)
            
            for frame_idx in range(num_frames):
                # å‰µå»ºå§¿å‹¢æ§åˆ¶
                pose_image = self.create_pose_conditioning(frame_idx)
                
                # ç”Ÿæˆå¹€
                frame = self.generate_character_frame(character_type, frame_idx, pose_image)
                frames.append(frame)
                
                # ä¿å­˜å–®å¹€
                frame_path = self.output_dir / f"{character_type}_frame_{frame_idx:02d}.png"
                frame.save(frame_path, "PNG")
                
                progress.update(task, advance=1, 
                              description=f"å·²ç”Ÿæˆ {character_type} ç¬¬ {frame_idx+1}/{num_frames} å¹€")
        
        console.print(f"âœ… {character_type} è¡Œèµ°é€±æœŸç”Ÿæˆå®Œæˆ", style="green")
        return frames
    
    def process_frame_for_pixel_art(self, image: Image.Image) -> Image.Image:
        """å¾Œè™•ç†åœ–åƒä»¥å¢å¼·åƒç´ è—è¡“æ•ˆæœ"""
        # è½‰æ›ç‚ºnumpyé™£åˆ—
        img_array = np.array(image)
        
        # ç°¡å–®çš„è‰²å½©é‡åŒ–
        # æ¸›å°‘é¡è‰²æ•¸é‡ä»¥ç²å¾—æ›´åƒç´ åŒ–çš„æ•ˆæœ
        img_array = img_array // 32 * 32
        
        # è½‰å›PILåœ–åƒ
        processed_img = Image.fromarray(img_array.astype(np.uint8))
        
        # ç¸®å°å¾Œæ”¾å¤§ä»¥å‰µå»ºåƒç´ æ•ˆæœ
        original_size = processed_img.size
        small_size = (original_size[0] // 8, original_size[1] // 8)
        
        processed_img = processed_img.resize(small_size, Image.NEAREST)
        processed_img = processed_img.resize(original_size, Image.NEAREST)
        
        return processed_img
    
    def generate_single_character(self, character_type: str):
        """ç”ŸæˆæŒ‡å®šè§’è‰²çš„è¡Œèµ°é€±æœŸ"""
        console.print(f"ğŸ¯ é–‹å§‹ç”Ÿæˆ {character_type} è§’è‰²è¡Œèµ°åœ–", style="bold magenta")
        
        # æª¢æŸ¥è§’è‰²æ˜¯å¦å­˜åœ¨æ–¼é…ç½®ä¸­
        if character_type not in self.config['prompts']['character_templates']:
            console.print(f"âŒ è§’è‰² '{character_type}' ä¸å­˜åœ¨æ–¼é…ç½®ä¸­", style="red")
            console.print("ğŸ“‹ å¯ç”¨è§’è‰²:", style="cyan")
            for char in self.config['prompts']['character_templates'].keys():
                console.print(f"   â€¢ {char}", style="cyan")
            return
        
        try:
            frames = self.generate_walk_cycle(character_type)
            
            # å¾Œè™•ç†å¢å¼·åƒç´ è—è¡“æ•ˆæœ
            processed_frames = []
            for frame in frames:
                processed_frame = self.process_frame_for_pixel_art(frame)
                processed_frames.append(processed_frame)
            
            # ä¿å­˜è™•ç†å¾Œçš„å¹€
            for i, frame in enumerate(processed_frames):
                frame_path = self.output_dir / f"{character_type}_processed_frame_{i:02d}.png"
                frame.save(frame_path, "PNG")
            
            console.print(f"âœ… {character_type} å®Œæˆ", style="green")
            
        except Exception as e:
            console.print(f"âŒ {character_type} ç”Ÿæˆå¤±æ•—: {e}", style="red")
        
        console.print(f"ğŸ‰ {character_type} è§’è‰²ç”Ÿæˆå®Œæˆï¼", style="bold green")
    
    def generate_all_characters(self):
        """ç”Ÿæˆæ‰€æœ‰è§’è‰²é¡å‹çš„è¡Œèµ°é€±æœŸ"""
        console.print("ğŸš€ é–‹å§‹ç”Ÿæˆæ‰€æœ‰è§’è‰²è¡Œèµ°åœ–", style="bold magenta")
        
        character_types = list(self.config['prompts']['character_templates'].keys())
        
        for char_type in character_types:
            try:
                frames = self.generate_walk_cycle(char_type)
                
                # å¾Œè™•ç†å¢å¼·åƒç´ è—è¡“æ•ˆæœ
                processed_frames = []
                for frame in frames:
                    processed_frame = self.process_frame_for_pixel_art(frame)
                    processed_frames.append(processed_frame)
                
                # ä¿å­˜è™•ç†å¾Œçš„å¹€
                for i, frame in enumerate(processed_frames):
                    frame_path = self.output_dir / f"{char_type}_processed_frame_{i:02d}.png"
                    frame.save(frame_path, "PNG")
                
                console.print(f"âœ… {char_type} å®Œæˆ", style="green")
                
            except Exception as e:
                console.print(f"âŒ {char_type} ç”Ÿæˆå¤±æ•—: {e}", style="red")
        
        console.print("ğŸ‰ æ‰€æœ‰è§’è‰²ç”Ÿæˆå®Œæˆï¼", style="bold green")
    
    def cleanup(self):
        """æ¸…ç†GPUè¨˜æ†¶é«”"""
        if self.pipe is not None:
            del self.pipe
        if self.controlnet is not None:
            del self.controlnet
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        console.print("ğŸ§¹ è¨˜æ†¶é«”æ¸…ç†å®Œæˆ", style="blue")

def main():
    """ä¸»å‡½æ•¸"""
    generator = SpriteGenerator()
    
    try:
        generator.generate_all_characters()
    finally:
        generator.cleanup()

if __name__ == "__main__":
    main() 